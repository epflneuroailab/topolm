# I/O
out_dir: "'out/'"
always_save_checkpoint: True
init_from: 'scratch'

# eval / logging stuff
eval_interval: 250
eval_iters: 200
save_interval: 500
log_interval: 50
eval_only: False

# data
radius: 5
neighborhoods_per_batch: 5
position_dir: "'gpt2-positions-' + str(radius) + '-' + str(neighborhoods_per_batch)"
dataset: 'fineweb'

batch_size: 48
block_size: 1024
gradient_accumulation_steps: 5 * 4

# model
n_layer: 12
n_head: 16
n_embed: 784
dropout: 0.0
bias: False
alpha: 2.5
accum: 'mean'
activation_decay: 0
head_loss: False
attn_proj: False
with_resid: True

# wandb logging
wandb_log: True
wandb_project: 'topo-gpt'
wandb_run_name: 'gpt2'

# adamw optimizer
learning_rate: 6e-4
max_iters: 600000
weight_decay: 1e-1
beta1: 0.9
beta2: 0.95
grad_clip: 1.0

# learning rate decay settings
decay_lr: True
warmup_iters: 2000
lr_decay_iters: 600000
min_lr: 6e-5

# DDP settings
backend: 'nccl' # 'nccl', 'gloo', etc.

# system
device: 'cuda'
dtype: "'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'"
compile: False