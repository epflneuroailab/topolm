{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae7cb26d-9f2a-4ecd-ae8d-d2f635e423a4",
   "metadata": {},
   "source": [
    "# preprocessing glue for fine-tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd00f21d-442d-487b-8900-6dde809e8e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import tiktoken\n",
    "import itertools\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b9c47c8-ac05-4abc-b921-61fbab0bcc0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(task):\n",
    "    \n",
    "    dataset = load_dataset(\"nyu-mll/glue\", task)\n",
    "    num_labels = len(dataset['train'].features['label'].names)\n",
    "    \n",
    "    return dataset, num_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d77b24a3-fef8-4cee-9596-e3dd6e4d8717",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, num_labels = get_dataset('cola')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "0f01bda7-2ffe-4237-985e-7f375d21bcd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def least_power_of_two(n):\n",
    "    return 1 << (n-1).bit_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4d4324a1-aadc-42c2-9bad-36cdab9e4242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(sents):\n",
    "    \n",
    "    tokens = tokenizer.encode_batch(sents, allowed_special='all')\n",
    "    \n",
    "    padded = list(zip(*itertools.zip_longest(*tokens, fillvalue=pad_token)))\n",
    "    padded = np.array(padded)\n",
    "    \n",
    "    attention_mask = (padded != pad_token).astype(int)\n",
    "        \n",
    "    return padded, attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3f82fdc7-cc8c-4b9c-960c-52e4197af21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randint(0, 10, (5, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a0f65659-d058-4e4c-9567-b5833a0cb815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 4, 0, 3, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randperm(x.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "107e7ff6-db18-467b-a08f-63a120213a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8, 8],\n",
       "        [0, 0],\n",
       "        [8, 7],\n",
       "        [7, 2],\n",
       "        [7, 2]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[torch.randperm(x.shape[0])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd2bc0ea-73e9-4591-beef-669f4b4e29bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "padded, mask = tokenize_batch(['the dog', 'went', 'to school', 'today in the store'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "c11df5db-72fc-4327-a744-80041fbcd125",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "n_batches  = 6\n",
    "dataloader = DataLoader(dataset['train'], batch_size = batch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "299023b2-b723-4000-81e6-707cb440394e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'sentence': ['That you will marry any particular student is not certain.'], 'label': tensor([1]), 'idx': tensor([1978])}\n",
      "{'sentence': ['Stephen seemed to be intelligent.'], 'label': tensor([1]), 'idx': tensor([4276])}\n"
     ]
    }
   ],
   "source": [
    "for i, batch in enumerate(dataloader):\n",
    "    print(batch)\n",
    "    break\n",
    "\n",
    "for i, batch in enumerate(dataloader):\n",
    "    print(batch)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f42ad77c-9f1f-49d7-bdcb-bea647e5ffcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63944d339d246a2aa30263c5408d93f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing the splits:   0%|          | 0/8551 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c402e876d9444c19a86781fdec604cb5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing the splits:   0%|          | 0/1043 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6ccc0f23024aa9a6eeb06fe8555cba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizing the splits:   0%|          | 0/1063 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenized = dataset.map(\n",
    "    process,\n",
    "    remove_columns=['sentence'],\n",
    "    desc=\"tokenizing the splits\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5d9d2be4-a301-4e25-ae24-2ba3130dd692",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'label': 1,\n",
       " 'idx': 0,\n",
       " 'ids': [5122,\n",
       "  2460,\n",
       "  1839,\n",
       "  470,\n",
       "  2822,\n",
       "  428,\n",
       "  3781,\n",
       "  11,\n",
       "  1309,\n",
       "  3436,\n",
       "  262,\n",
       "  1306,\n",
       "  530,\n",
       "  356,\n",
       "  18077,\n",
       "  13,\n",
       "  50256],\n",
       " 'len': 17}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for split, dset in tokenized.items():\n",
    "    arr_len = np.sum(dset['len'], dtype=np.uint64)\n",
    "    filename = os.path.join(os.path.dirname(__file__), f'{split}.bin')\n",
    "    dtype = np.uint16 # (can do since enc.max_token_value == 50256 is < 2**16)\n",
    "    arr = np.memmap(filename, dtype=dtype, mode='w+', shape=(arr_len,))\n",
    "    total_batches = 1024\n",
    "\n",
    "    idx = 0\n",
    "    for batch_idx in tqdm(range(total_batches), desc=f'writing {filename}'):\n",
    "        # Batch together samples for faster write\n",
    "        batch = dset.shard(num_shards=total_batches, index=batch_idx, contiguous=True).with_format('numpy')\n",
    "        arr_batch = np.concatenate(batch['ids'])\n",
    "        # Write into mmap\n",
    "        arr[idx : idx + len(arr_batch)] = arr_batch\n",
    "        idx += len(arr_batch)\n",
    "    arr.flush()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
