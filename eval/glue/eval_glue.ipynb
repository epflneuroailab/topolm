{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a4f6f27f-b00e-4181-bea0-0b9e37ea8bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import tiktoken\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle as pkl\n",
    "\n",
    "sys.path.insert(1, '../../models/')\n",
    "from model import GPT, GPTConfig\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6bd4989-aeb5-49f9-85ab-bc34d2335c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17c2b039-cb0f-4ba8-920a-efdf637dfe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tasks = ['cola', 'sst2', 'mrpc', 'qqp', 'stsb', 'mnli', 'qnli', 'rte', 'wnli']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "656ed87c-6293-48cd-9666-f7f6d073da94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of parameters: 127.97M\n"
     ]
    }
   ],
   "source": [
    "checkpoint = torch.load('../../models/out/ckpt-5-5-2.5-48-mean-0.pt', map_location=device)\n",
    "model_args = checkpoint['model_args']\n",
    "model_args['position_dir'] = '../../models/gpt2-positions-5-5'\n",
    "model_args['dropout'] = 0.1\n",
    "\n",
    "gptconf = GPTConfig(**model_args)\n",
    "model = GPT(gptconf)\n",
    "\n",
    "state_dict = checkpoint['model']\n",
    "# fix the keys of the state dictionary :(\n",
    "# honestly no idea how checkpoints sometimes get this prefix, have to debug more\n",
    "unwanted_prefix = '_orig_mod.'\n",
    "for k,v in list(state_dict.items()):\n",
    "    if k.startswith(unwanted_prefix):\n",
    "        state_dict[k[len(unwanted_prefix):]] = state_dict.pop(k)\n",
    "\n",
    "model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "pad_token = tokenizer.encode('<|endoftext|>', allowed_special=\"all\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7f3c5034-feb3-43e8-9acc-229ce427c301",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"nyu-mll/glue\", \"mnli\").with_format(\"torch\")\n",
    "num_labels = len(ds['train'].features['label'].names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b51d154-85f8-4fa9-a5ae-a4a5518a6fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_batch(sents):\n",
    "    tokens = tokenizer.encode_batch(sents, allowed_special = 'all')\n",
    "    padded = list(zip(*itertools.zip_longest(*tokens, fillvalue=pad_token)))\n",
    "    return torch.from_numpy(np.array(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fec25408-35c6-4d5d-8ae5-4e274cd22771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([48, 97])\n",
      "torch.Size([48])\n"
     ]
    }
   ],
   "source": [
    "dataloader = DataLoader(ds['train'], batch_size=48)\n",
    "for batch in dataloader:\n",
    "    sents = ['<|endoftext|>'.join(x) for x in zip(batch['premise'], batch['hypothesis'])]\n",
    "    X = tokenize_batch(sents)\n",
    "    Y = batch['label']\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4c5327dc-d7dd-4de1-a163-025c3948f920",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['premise', 'hypothesis', 'label', 'idx'],\n",
       "    num_rows: 392702\n",
       "})"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cf568bb-4df2-44c9-882b-fcf70715991b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 0.0148,  0.0097, -0.0079,  ..., -0.0020,  0.0441, -0.0429],\n",
       "        [-0.0126, -0.0165,  0.0046,  ...,  0.0212, -0.0085,  0.0061],\n",
       "        [-0.0013, -0.0004,  0.0201,  ..., -0.0292, -0.0147,  0.0081]],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.lm_head = torch.nn.Linear(in_features = model.lm_head.in_features,\n",
    "                                out_features = num_labels,\n",
    "                                bias = model.lm_head.bias)\n",
    "torch.nn.init.normal_(model.lm_head.weight, mean=0.0, std=0.02)\n",
    "\n",
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f804ee60-d931-4c16-b074-60a14f2018e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 6e-4 # max learning rate\n",
    "weight_decay = 1e-1\n",
    "beta1 = 0.9\n",
    "beta2 = 0.95\n",
    "grad_clip = 1.0 # clip gradients at this value, or disable if:= 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f4f4bfa5-fd7a-4302-af3f-f11896507362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num decayed parameter tensors: 51, with 128,753,968 parameters\n",
      "num non-decayed parameter tensors: 25, with 19,600 parameters\n",
      "using fused AdamW: False\n"
     ]
    }
   ],
   "source": [
    "dtype = 'bfloat16' if torch.cuda.is_available() and torch.cuda.is_bf16_supported() else 'float16'\n",
    "device_type = 'cpu' # for later use in torch.autocast\n",
    "\n",
    "scaler = torch.cuda.amp.GradScaler(enabled=(dtype == 'float16'))\n",
    "optimizer = model.configure_optimizers(weight_decay, learning_rate, (beta1, beta2), device_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "43ec0226-5449-4e13-b67b-8be54bdc528b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained('facebook/bart-large-mnli')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48eca6c4-f675-4e2e-9695-a015d6344c82",
   "metadata": {},
   "outputs": [],
   "source": [
    "premise = 'one day I will see the world'\n",
    "hypothesis = 'This example is travel.'\n",
    "\n",
    "# run through model pre-trained on MNLI\n",
    "x = tokenizer.encode(premise, hypothesis, return_tensors='pt',\n",
    "                     truncation_strategy='only_first')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "48c175cb-16f1-4be5-b826-8498e948b998",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<s>one day I will see the world</s></s>This example is travel.</s>'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(x[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
